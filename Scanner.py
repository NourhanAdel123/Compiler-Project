# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FbnB75Kzd7fpyMDiPJnbqucizGTIC6dN
"""

import re

PATTERNS = [
    ('RESERVED', r'\b(int|return|if|else|for|while|do|break|continue|printf)\b'),
    ('VAR', r'\b[a-zA-Z_]\w*\b'),
    ('NUMBER', r'\b\d+\b'),
    ('OP', r'[+\-*/=<>]'),
    ('STRING', r'"[^"]*"'),
    ('SPECIAL_CHAR', r'[{}();\[\],.]'),
    ('SPACE', r'[ \t]+'),
    ('LINE_BREAK', r'\n'),
]

combined_regex = '|'.join(f'(?P<{pair[0]}>{pair[1]})' for pair in PATTERNS)
tokenize = re.compile(combined_regex)

def tokenize_code(source_code):
    line = 1
    current_pos = 0
    token_list = []

    while current_pos < len(source_code):
        matched = tokenize.match(source_code, current_pos)
        if matched is None:
            print(f"Unexpected character at position {current_pos}")
            break

        token_type = matched.lastgroup
        if token_type == 'LINE_BREAK':
            line += 1
        elif token_type != 'SPACE':
            token_value = matched.group(token_type)
            token_list.append((token_type, token_value, line))

        current_pos = matched.end()

    return token_list

c_program = """
int main() {
   for (int i = 0; i < 10; i++) {
      printf("Hello, World!\\n");
   }
   return 0;
}
"""

token_output = tokenize_code(c_program)

for tok in token_output:
    print(tok)